'''
class HDPipeline:
    def __init__(self):
        with open('/home/meclab/Autoware/ros/src/computing/perception/detection/vision_detector/packages/vision_lane_detect/script/Calibration.yml', 'r') as stream:
            cam_data = yaml.load(stream)
        self.cameraExtrinsicMat = np.reshape(cam_data['CameraExtrinsicMat']['data'], (4, 4))
        self.cameraMat = np.reshape(cam_data['CameraMat']['data'], (3, 3))
        self.imageSize = cam_data['ImageSize']
        self.distCoeff = cam_data['DistCoeff']
        self.reProjectionError = cam_data['ReprojectionError']

        self.car_origin = [-8172.4245951511, 6788.6478131412, -45.7949960938]
        self.car_position_Time = []
        self.car_position_NED = []
        self.edge_NE = []
        self.central_NE = []

        car_position_file = '/home/meclab/Autoware/ros/src/computing/perception/detection/vision_detector/packages/vision_lane_detect/script/position_data/car_position.xls'
        edge_file = '/home/meclab/Autoware/ros/src/computing/perception/detection/vision_detector/packages/vision_lane_detect/script/position_data/sl_edge.xls'
        central_file = '/home/meclab/Autoware/ros/src/computing/perception/detection/vision_detector/packages/vision_lane_detect/script/position_data/sl_central.xls'

        car_position_df = pd.read_excel(car_position_file)
        edge_df = pd.read_excel(edge_file)
        central_df = pd.read_excel(central_file)

        self.car_position_Time = car_position_df.iloc[:, 6]
        self.car_position_NED = np.array(car_position_df.iloc[:, 0:3])
        self.edge_NE = np.array(edge_df.iloc[:, 0:2])
        self.central_NE = np.array(central_df.iloc[:, 0:2])
        
        self.car_last_position = self.car_origin[0:2]
        self.i = 0
        self.c = 0

        #---------------------------------- Load model
        self.input_tensor = tf.placeholder(dtype=tf.float32, shape=[1, 256, 512, 3], name='input_tensor')
        self.phase_tensor = tf.constant('test', tf.string)
        net = lanenet_merge_model.LaneNet(phase = self.phase_tensor, net_flag='vgg')
        self.binary_seg_ret, self.instance_seg_ret = \
                                net.inference(input_tensor = self.input_tensor, name = 'lanenet_model')
        self.cluster = lanenet_cluster.LaneNetCluster()
        self.postprocessor = lanenet_postprocess.LaneNetPoseProcessor()
        saver = tf.train.Saver()

        #---------------------------------- Set session configuration
        '''
        if use_gpu:
            sess_config = tf.ConfigProto(device_count={'GPU': 1})
        else:
            sess_config = tf.ConfigProto(device_count={'CPU': 0})
        '''
        #sess_config = tf.ConfigProto(device_count={'CPU': 1})# ***************************
        sess_config = tf.ConfigProto(device_count={'GPU': 1})

        sess_config.gpu_options.per_process_gpu_memory_fraction = CFG.TEST.GPU_MEMORY_FRACTION
        sess_config.gpu_options.allow_growth = CFG.TRAIN.TF_ALLOW_GROWTH
        sess_config.gpu_options.allocator_type = 'BFC'
        self.sess = tf.Session(config = sess_config)
        saver.restore(sess = self.sess, save_path = '/home/meclab/Autoware/ros/src/computing/perception/detection/vision_detector/packages/vision_lane_detect/script/model/tusimple_lanenet/tusimple_lanenet_vgg_2018-10-19-13-33-56.ckpt-200000')

        #---------------------------------- Set topic
        self.image_pub = rospy.Publisher("laneNet_discrepancy", Image)
        self.bridge = CvBridge()

        image_topic_name = '/image_raw'
        rospy.loginfo('Setting image topic to %s', image_topic_name)
        self.image_sub = rospy.Subscriber(image_topic_name, Image, self.laneNet_callback)

    def world_to_camera(self, lane_points, lidar):
        X = lane_points[0] - lidar[0]
        Y = lane_points[1] - lidar[1]
        Z = 1.55
        worldCoord = np.array([X, Y, Z, 1])
        return np.dot(self.cameraExtrinsicMat, worldCoord)

    def camera_to_image(self, cameraCoord):

        return np.dot(self.cameraMat, cameraCoord)

    def front_direction_estimation(self, now_position, last_position):
        estimate_range = 4 #meter
        to_lidar_range = 1.72 #meter
        ne_vector = now_position - last_position # Vector of the car's heading
        distance = (((ne_vector[0]) ** 2 + (ne_vector[1]) ** 2) ** 0.5)
        ratio_to_one_meter = 1 / (((ne_vector[0]) ** 2 + (ne_vector[1]) ** 2) ** 0.5)
        unit_NE_vector = ne_vector * ratio_to_one_meter
        point1 = now_position + unit_NE_vector * estimate_range
        point2 = now_position + unit_NE_vector * to_lidar_range
        return point1, point2, ne_vector, distance

    def sort_closet_to_farthest(self, p, lane):
        d = (((lane[:] - p)[:, 0]) ** 2 + ((lane[:] - p)[:, 1]) ** 2) ** 0.5
        d = d.tolist()
        lane = lane.tolist()
        for idx, i in enumerate(lane):
            i.append(d[idx])
        
        lane = sorted(lane, key = lambda x: x[2])
        
        sorted_lane = []
        for j in lane:
            sorted_lane.append(j[0:2])
        
        return np.array(sorted_lane)

    def find_center_lane_point(self, central_NE, point, ne_vector):
        measure_range = 4 #meter
        distance = (((central_NE[:] - point)[:, 0]) ** 2 + ((central_NE[:] - point)[:, 1]) ** 2) ** 0.5 # Distance of central lanes to the base point, which is 4 meters in front of the car.
        #lane_point = central_NE[distance < measure_range] # Find the distance which is in range of 4 meters.
        lane_point = self.sort_closet_to_farthest(point, central_NE[distance < measure_range])
        '''
        front_lane = []
        for i in lane_point:
            a_vec = i - point #
            b_vec = ne_vector # Vector of the car's heading
            a_len = (a_vec[0] ** 2 + a_vec[1] ** 2) ** 0.5
            b_len = (b_vec[0] ** 2 + b_vec[1] ** 2) ** 0.5
            cosine = np.dot(a_vec, b_vec) / ((a_len) * (b_len))
            if cosine >= 0:
                front_lane.append(i)
        #print('----------')
        #print(lane_point)
        #print('----------')
        
        front_lane = np.array(front_lane)
        #print(front_lane)
        return front_lane
        '''
        return lane_point

    def find_edge_lane_point(self, edge_NE, point, ne_vector):
        measure_range = 4 #meterwhat 
        distance = (((edge_NE[:] - point)[:, 0]) ** 2 + ((edge_NE[:] - point)[:, 1]) ** 2) ** 0.5 # Distance of central lanes to the base point, which is 4 meters in front of the car.
        #lane_point = edge_NE[distance < measure_range] # Find the distance which is in range of 4 meters.
        lane_point = self.sort_closet_to_farthest(point, edge_NE[distance < measure_range])
        '''
        front_lane = []
        for i in lane_point:
            a_vec = i - point #
            b_vec = ne_vector # Vector of the car's heading
            a_len = (a_vec[0] ** 2 + a_vec[1] ** 2) ** 0.5
            b_len = (b_vec[0] ** 2 + b_vec[1] ** 2) ** 0.5
            cosine = np.dot(a_vec, b_vec) / ((a_len) * (b_len))
            if cosine >= 0:
                front_lane.append(i)
        #print('----------')
        #print(lane_point)
        #print('----------')
        
        front_lane = np.array(front_lane)
        #print(front_lane)
        return front_lane
        '''
        return lane_point

    def HD_map_pipeline(self):
        
        #center_lane_points = []
        #edge_lane_points = []
        self.car_now_position = self.car_position_NED[self.i][0:2]
        base_point, lidar_point, NE_vector, displacement = self.front_direction_estimation(self.car_now_position, self.car_last_position)
        self.car_last_position = self.car_now_position
        
        image_center_lane = []
        image_edge_lane = []
        if (displacement > 0.25):
            center_lane_points = self.find_center_lane_point(self.central_NE, base_point, NE_vector)
            edge_lane_points = self.find_edge_lane_point(self.edge_NE, base_point, NE_vector)

            ### Center lane coordinate transformation
            for j in center_lane_points:
                cameraCoord = self.world_to_camera(j, lidar_point) # World coordinate to camera coordinate.
                imageCoord = self.camera_to_image(cameraCoord[0:3]) # Camera coordinate to image coordinate.

                imageCoord = ((imageCoord / imageCoord[-1])[0:2])
                if (imageCoord[0] < self.imageSize[0] and imageCoord[0] > 0) and (imageCoord[1] < self.imageSize[1] and imageCoord[1] > 0):
                    imageCoord[0] = round(imageCoord[0])
                    imageCoord[1] = round(imageCoord[1])
                    image_center_lane.append(imageCoord)
                cameraCoord = []
                imageCoord = []
                #print(imageCoord)
            image_center_lane = np.array(image_center_lane)

            ### Edge lane coordinate transformation
            for m in edge_lane_points:
                cameraCoord = self.world_to_camera(m, lidar_point) # World coordinate to camera coordinate.
                #print(cameraCoord)
                imageCoord = self.camera_to_image(cameraCoord[0:3]) # Camera coordinate to image coordinate.

                imageCoord = ((imageCoord / imageCoord[-1])[0:2])
                if (imageCoord[0] < self.imageSize[0] and imageCoord[0] > 0) and (imageCoord[1] < self.imageSize[1] and imageCoord[1] > 0):
                    imageCoord[0] = round(imageCoord[0])
                    imageCoord[1] = round(imageCoord[1])
                    image_edge_lane.append(imageCoord)
                cameraCoord = []
                imageCoord = []
                #print(imageCoord)
            image_edge_lane = np.array(image_edge_lane)

        return image_center_lane, image_edge_lane


    def laneNet_inference(self, frame):
        frame_vis = cv2.resize(frame, (512, 256))
        frame = cv2.resize(frame, (512, 256), interpolation = cv2.INTER_LINEAR) - VGG_MEAN
        
        #---------------------------------- Do inference
        t_start = time.time()
        binary_seg_frame, instance_seg_frame = self.sess.run([self.binary_seg_ret, self.instance_seg_ret], \
                                                        feed_dict={self.input_tensor: [frame]})
        t_cost = time.time() - t_start
        rospy.loginfo('Inference time: {} second'.format(t_cost))

        binary_seg_frame[0] = self.postprocessor.postprocess(binary_seg_frame[0])
        mask_frame = self.cluster.get_lane_mask(binary_seg_ret = binary_seg_frame[0], \
                                        instance_seg_ret = instance_seg_frame[0])
        output_frame = cv2.addWeighted(frame_vis, 1, mask_frame, 1, 0)

        #---------------------------------- Get the discrepancy lanes
        center_lane, edge_lane = self.HD_map_pipeline()

        #---------------------------------- Plot the discrepancy lanes
        cv2.resize(output_frame, (self.imageSize[0], self.imageSize[1]))

        for kdx, k in enumerate(center_lane):
            if kdx + 1 == len(center_lane):
                break
            cv2.line(output_frame, (int(center_lane[kdx][0]), int(center_lane[kdx][1])), \
            (int(center_lane[kdx + 1][0]), int(center_lane[kdx + 1][1])), (0, 100, 255), thickness = 2)
                
        for ldx, l in enumerate(edge_lane):
            if ldx + 1 == len(edge_lane):
                break
            cv2.line(output_frame, (int(edge_lane[ldx][0]), int(edge_lane[ldx][1])), \
            (int(edge_lane[ldx + 1][0]), int(edge_lane[ldx + 1][1])), (0, 100, 255), thickness = 2)

        #---------------------------------- Publish the output image
        try:
            self.image_pub.publish(self.bridge.cv2_to_imgmsg(output_frame, 'bgr8'))
        except CvBridgeError as e:
            print(e)
        
    def laneNet_callback(self, data):
        try:
            cv_image = CvBridge().imgmsg_to_cv2(data, "bgr8")
        except CvBridgeError as e:
            print(e)
        
        #---------------------------------- Do inference per second
        if (self.c % 20 == 0):
            self.laneNet_inference(cv_image)
            self.i = self.i + 1
        #rospy.loginfo('Time: {} m second'.format(self.c))
        self.c = self.c + 1
        cv2.waitKey(1)
    
    def main(self):
        rospy.spin()
'''
